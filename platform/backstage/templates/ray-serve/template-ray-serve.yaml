apiVersion: scaffolder.backstage.io/v1beta3
kind: Template
metadata:
  description: |
    Deploy Ray Service on Kubernetes using Kro abstraction and GitOps.
    
    **Recommended Resources by Model:**
    
    | Model | Size | CPU | Memory | GPU | Use Case |
    |-------|------|-----|--------|-----|----------|
    | DialoGPT-medium | 1.4GB | 2 | 4Gi | 0 | Conversational |
    | Phi-2 | 5.5GB | 4 | 8Gi | 0 | Technical Q&A |
    | TinyLlama | 2.2GB | 4 | 8Gi | 0 | Fast inference |
    | Mistral-7B | 14GB | 8 | 48Gi | 1 | High quality |
    | Llama-2-7B | 13GB | 8 | 48Gi | 1 | Strong performance |
    
    Note: Memory requirements include model weights + inference overhead (2-3x model size).
  name: ray-serve-kubernetes
  title: Ray Service on Kubernetes
spec:
  owner: guest
  type: service
  parameters:
    - title: Ray Service Configuration
      description: Basic configuration for your Ray Service
      properties:
        name:
          title: Service Name
          description: Name of the Ray Service (lowercase, alphanumeric, hyphens allowed)
          type: string
          pattern: '^[a-z0-9][a-z0-9-]*[a-z0-9]$|^[a-z0-9]$'
          minLength: 1
          maxLength: 63
          ui:help: 'Must be lowercase alphanumeric with hyphens, 1-63 characters'
        rayServeFile:
          title: Ray Serve Config
          description: URL to your Ray Service Multi-application config zip file
          type: string
          default: "https://github.com/aws-samples/appmod-blueprints/raw/refs/heads/feat/eks-capabilities-squash/gitops/workloads/ray/gpu-demo-serve-config.zip"
          ui:help: 'URL to zip file containing Ray Serve application code'
      required:
        - name
    - title: Deployment Configuration
      description: Configure deployment settings for your Ray Service
      properties:
        namespace:
          title: Kubernetes Namespace
          description: Namespace where the Ray Service will be deployed
          type: string
          default: ray-system
          pattern: '^[a-z0-9][a-z0-9-]*[a-z0-9]$|^[a-z0-9]$'
          ui:help: 'Kubernetes namespace for Ray Service deployment'
        replicas:
          title: Worker Replicas
          description: Number of Ray worker replicas
          type: integer
          default: 2
          minimum: 1
          maximum: 10
          ui:help: 'Number of Ray worker pods to deploy'
    - title: Model Configuration
      description: Select the AI model for text generation
      properties:
        modelId:
          title: Model Selection
          description: Choose the AI model based on your resource availability
          type: string
          default: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
          enum:
            - "microsoft/DialoGPT-medium"
            - "microsoft/phi-2"
            - "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
            - "mistralai/Mistral-7B-Instruct-v0.2"
            - "meta-llama/Llama-2-7b-chat-hf"
          enumNames:
            - "DialoGPT-medium (CPU) - 345M params, ~1.4GB - Conversational"
            - "Phi-2 (CPU) - 2.7B params, ~5.5GB - Technical Q&A"
            - "TinyLlama (CPU) - 1.1B params, ~2.2GB - Fast & Efficient"
            - "Mistral-7B (GPU) - 7B params, ~14GB - High Quality (Requires 48GB RAM + GPU)"
            - "Llama-2-7B (GPU) - 7B params, ~13GB - Strong Performance (Requires 48GB RAM + GPU)"
          ui:help: 'Model size includes weights only. Total memory needs are 2-3x higher with inference overhead.'
        maxLength:
          title: Max Generation Length
          description: Maximum number of tokens to generate
          type: string
          default: "100"
          ui:help: 'Higher values generate longer responses but take more time (50-500)'
    - title: Resource Configuration
      description: Configure CPU and memory resources (defaults set based on model selection)
      dependencies:
        modelId:
          oneOf:
            - properties:
                modelId:
                  enum:
                    - "microsoft/DialoGPT-medium"
                workerCpu:
                  default: "2"
                workerMemory:
                  default: "4Gi"
                workerGpu:
                  default: "0"
            - properties:
                modelId:
                  enum:
                    - "microsoft/phi-2"
                workerCpu:
                  default: "4"
                workerMemory:
                  default: "8Gi"
                workerGpu:
                  default: "0"
            - properties:
                modelId:
                  enum:
                    - "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
                workerCpu:
                  default: "4"
                workerMemory:
                  default: "8Gi"
                workerGpu:
                  default: "0"
            - properties:
                modelId:
                  enum:
                    - "mistralai/Mistral-7B-Instruct-v0.2"
                workerCpu:
                  default: "8"
                workerMemory:
                  default: "48Gi"
                workerGpu:
                  default: "1"
            - properties:
                modelId:
                  enum:
                    - "meta-llama/Llama-2-7b-chat-hf"
                workerCpu:
                  default: "8"
                workerMemory:
                  default: "48Gi"
                workerGpu:
                  default: "1"
      properties:
        headCpu:
          title: Head CPU
          description: CPU request for Ray head pod
          type: string
          default: "2"
          pattern: '^[0-9]+(\.[0-9]+)?[m]?$|^[0-9]+$'
          ui:help: 'CPU cores (e.g., "1", "2", "500m") - Head pod coordinates workers'
        headMemory:
          title: Head Memory
          description: Memory request for Ray head pod
          type: string
          default: "8Gi"
          ui:help: 'Memory size (e.g., "4Gi", "8Gi") - Head pod needs minimal memory'
        workerCpu:
          title: Worker CPU
          description: CPU request for Ray worker pods (recommended based on model)
          type: string
          default: "4"
          pattern: '^[0-9]+(\.[0-9]+)?[m]?$|^[0-9]+$'
          ui:help: |
            Recommended by model:
            - DialoGPT/Phi-2/TinyLlama: 2-4 CPU
            - Mistral-7B/Llama-2-7B: 8 CPU
        workerMemory:
          title: Worker Memory
          description: Memory request for Ray worker pods (recommended based on model)
          type: string
          default: "16Gi"
          ui:help: |
            Recommended by model:
            - DialoGPT: 4Gi
            - Phi-2: 8Gi  
            - TinyLlama: 8Gi
            - Mistral-7B: 48Gi
            - Llama-2-7B: 48Gi
        workerGpu:
          title: Worker GPU
          description: GPU request for Ray worker pods
          type: string
          default: "0"
          enum:
            - "0"
            - "1"
          enumNames:
            - "No GPU (CPU models only)"
            - "1 GPU (Required for Mistral-7B, Llama-2-7B)"
          ui:help: 'GPU models (Mistral, Llama) require GPU=1 and 48Gi memory'
  steps:
    - id: validate-parameters
      name: Validate Parameters
      action: debug:log
      input:
        message: |
          Validating template parameters:
          - Service Name: ${{ parameters.name }}
          - Namespace: ${{ parameters.namespace }}
          - Ray Serve Config: ${{ parameters.rayServeFile }}
          - Worker Replicas: ${{ parameters.replicas }}
          - Head Resources: ${{ parameters.headCpu }}/${{ parameters.headMemory }}
          - Worker Resources: ${{ parameters.workerCpu }}/${{ parameters.workerMemory }}

    - id: fetchSystem
      name: Fetch System
      action: catalog:fetch
      input:
        entityRef: system:default/system-info

    - action: fetch:template
      name: Fetch Base
      id: fetch-base
      input:
        url: ./skeleton/
        values:
          name: ${{ parameters.name }}
          namespace: ${{ parameters.namespace }}
          modelId: ${{ parameters.modelId }}
          maxLength: ${{ parameters.maxLength }}
          rayServeFile: ${{ parameters.rayServeFile }}
          replicas: ${{ parameters.replicas }}
          headCpu: ${{ parameters.headCpu }}
          headMemory: ${{ parameters.headMemory }}
          workerCpu: ${{ parameters.workerCpu }}
          workerMemory: ${{ parameters.workerMemory }}
          headGpu: "0"
          workerGpu: ${{ parameters.workerGpu }}
          gitlab_hostname: ${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}
          ingress_hostname: ${{ steps['fetchSystem'].output.entity.spec.ingress_hostname }}
          argocd_hostname: ${{ steps['fetchSystem'].output.entity.spec.argocd_hostname }}
          git_username: ${{ steps['fetchSystem'].output.entity.spec.gituser }}
          aws_account_id: ${{ steps['fetchSystem'].output.entity.spec.aws_account_id }}
          aws_region: ${{ steps['fetchSystem'].output.entity.spec.aws_region }}
          created_by: ${{ user.entity.metadata.name | default("unknown") }}

    - id: publish
      name: Publishing to GitLab repository
      action: publish:gitlab
      input:
        repoUrl: ${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}?repo=${{parameters.name}}-ray-service&owner=${{ steps['fetchSystem'].output.entity.spec.gituser }}
        defaultBranch: main
        useCustomGit: true

    - id: create-argocd-project
      name: Create ArgoCD Project
      action: kube:apply
      input:
        namespaced: true
        manifest: |
          apiVersion: argoproj.io/v1alpha1
          kind: AppProject
          metadata:
            name: ${{parameters.name}}-ray-project
            namespace: argocd
            labels:
              app.kubernetes.io/name: ${{parameters.name}}
              app.kubernetes.io/component: ray-service
              app.kubernetes.io/managed-by: backstage
              backstage.io/template-name: ray-serve-kubernetes
            annotations:
              backstage.io/template-version: "1.0.0"
              backstage.io/created-by: ${{ user.entity.metadata.name | default("unknown") }}
          spec:
            destinations:
              - name: peeks-hub
                namespace: ${{ parameters.namespace }}
            sourceRepos:
              - https://${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}/${{ steps['fetchSystem'].output.entity.spec.gituser }}/${{parameters.name}}-ray-service.git
            sourceNamespaces:
              - argocd
            namespaceResourceWhitelist:
              - group: ""
                kind: Namespace
              - group: ""
                kind: Service
              - group: ""
                kind: ConfigMap
              - group: ""
                kind: Secret
              - group: apps
                kind: Deployment
              - group: kro.run
                kind: RayService
              - group: ray.io
                kind: RayService
              - group: ray.io
                kind: RayCluster
              - group: networking.k8s.io
                kind: Ingress
            roles:
              - name: admin
                policies:
                  - p, proj:${{parameters.name}}-ray-project:admin, applications, *, ${{parameters.name}}-ray-project/*, allow
                  - p, proj:${{parameters.name}}-ray-project:admin, repositories, *, *, allow
                groups:
                  - eks-argocd-admins
              - name: developer
                policies:
                  - p, proj:${{parameters.name}}-ray-project:developer, applications, get, ${{parameters.name}}-ray-project/*, allow
                  - p, proj:${{parameters.name}}-ray-project:developer, applications, sync, ${{parameters.name}}-ray-project/*, allow
                  - p, proj:${{parameters.name}}-ray-project:developer, repositories, get, *, allow
                groups:
                  - eks-argocd-developers

    - id: create-argocd-app
      name: Create ArgoCD Application (GitOps)
      action: kube:apply
      input:
        namespaced: true
        manifest: |
          apiVersion: argoproj.io/v1alpha1
          kind: Application
          metadata:
            name: ${{parameters.name}}-ray-service
            namespace: argocd
            labels:
              app.kubernetes.io/name: ${{parameters.name}}
              app.kubernetes.io/component: ray-service
              app.kubernetes.io/managed-by: backstage
              backstage.io/template-name: ray-serve-kubernetes
            annotations:
              backstage.io/template-version: "1.0.0"
              backstage.io/created-by: ${{ user.entity.metadata.name | default("unknown") }}
              argocd.argoproj.io/finalizer: resources-finalizer.argocd.argoproj.io
          spec:
            project: ${{parameters.name}}-ray-project
            source:
              repoURL: https://${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}/${{ steps['fetchSystem'].output.entity.spec.gituser }}/${{parameters.name}}-ray-service.git
              path: manifests
              targetRevision: HEAD
            destination:
              name: peeks-hub
              namespace: ${{ parameters.namespace }}
            syncPolicy:
              automated:
                prune: true
                selfHeal: true
              syncOptions:
                - CreateNamespace=true
                - PrunePropagationPolicy=foreground
                - PruneLast=true
              retry:
                limit: 5
                backoff:
                  duration: 5s
                  factor: 2
                  maxDuration: 3m
            ignoreDifferences:
              - group: kro.run
                kind: RayService
                jsonPointers:
                  - /status
              - group: ray.io
                kind: RayService
                jsonPointers:
                  - /status
              - group: ray.io
                kind: RayCluster
                jsonPointers:
                  - /status
            info:
              - name: 'Kro RayService Status'
                value: 'Check the RayService resource status for detailed information'

    - id: register
      name: Register
      action: catalog:register
      input:
        repoContentsUrl: https://${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}/${{ steps['fetchSystem'].output.entity.spec.gituser }}/${{parameters.name}}-ray-service/-/blob/main
        catalogInfoPath: "/catalog-info.yaml"

    - id: wait-for-sync
      name: Wait for Initial Sync
      action: debug:log
      input:
        message: |
          üîÑ **GitOps Deployment Initiated!**
          
          Your Ray Service is now being deployed via GitOps using ArgoCD and Kro abstraction. 
          The Kro RayService resource will be created and managed by ArgoCD, orchestrating 
          all required Kubernetes and Ray resources.
          
          ## üìä **Kro + GitOps Benefits**
          - ‚úÖ **High-Level Abstraction**: Single RayService resource manages everything
          - ‚úÖ **Full Visibility**: All resources appear in ArgoCD applications
          - ‚úÖ **Version Control**: All changes tracked in Git
          - ‚úÖ **Rollback Capability**: Easy rollback to previous versions
          - ‚úÖ **Drift Detection**: ArgoCD monitors and corrects configuration drift
          - ‚úÖ **Resource Orchestration**: Kro handles complex resource dependencies
          
          ## üîç **Monitoring Deployment**
          1. **ArgoCD Application**: Monitor sync status and health
          2. **Kro Resource Status**: Check RayService resource conditions
          3. **Ray Resources**: Watch Ray cluster and serve pods being created
          
          The ArgoCD application will automatically sync and create the Kro RayService resource,
          which will then orchestrate the creation of all required Ray and Kubernetes resources.

  output:
    links:
      - title: Open in catalog
        icon: catalog
        entityRef: ${{ steps['register'].output.entityRef }}
      - title: ArgoCD Application (GitOps)
        url: https://${{ steps['fetchSystem'].output.entity.spec.argocd_hostname }}/applications/${{ parameters.name }}-ray-service?resource=
        icon: web
      - title: GitLab Repository (GitOps Source)
        url: https://${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}/${{ steps['fetchSystem'].output.entity.spec.gituser }}/${{ parameters.name }}-ray-service
        icon: git
      - title: ArgoCD Project
        url: https://${{ steps['fetchSystem'].output.entity.spec.argocd_hostname }}/settings/projects/${{ parameters.name }}-ray-project
        icon: web
      - title: Ray Serve Endpoint (After Deployment)
        url: https://${{ steps['fetchSystem'].output.entity.spec.ingress_hostname }}/ray-serve/${{ parameters.name }}/
        icon: web
      - title: Ray Dashboard (After Deployment)
        url: https://${{ steps['fetchSystem'].output.entity.spec.ingress_hostname }}/ray-dashboard/${{ parameters.name }}/
        icon: web
    text:
      - title: Kro-based Ray Service Deployment
        content: |
          üéâ **Kro + GitOps Ray Service Successfully Initiated!**
          
          Your Ray Service is now being deployed using Kro abstraction with GitOps principles. 
          This approach provides the highest level of automation and management capabilities.
          
          ## üîÑ **Kro + GitOps Workflow**
          1. **Repository Created**: GitLab repository with Kro RayService manifest
          2. **ArgoCD Application**: Monitors repository for changes
          3. **Automatic Sync**: ArgoCD deploys Kro RayService resource
          4. **Kro Orchestration**: RayService creates all required resources
          5. **Continuous Monitoring**: ArgoCD ensures desired state
          
          ## üìä **Key Advantages**
          
          ### **Kro Abstraction Benefits**
          - **Simplified Management**: Single resource manages complex Ray deployment
          - **Resource Orchestration**: Automatic dependency handling and ordering
          - **Status Aggregation**: Unified status across all managed resources
          - **Lifecycle Management**: Coordinated creation, updates, and deletion
          
          ### **GitOps Benefits**
          - **Version Control**: All configuration changes tracked in Git
          - **Rollback**: Easy rollback to any previous version
          - **Audit Trail**: Complete history of who changed what and when
          - **Drift Detection**: ArgoCD automatically corrects configuration drift
          
          ### **Enhanced Management**
          - **Declarative**: Infrastructure as Code approach
          - **Reproducible**: Consistent deployments across environments
          - **Scalable**: Easy to replicate for multiple Ray Services
          
          ## üöÄ **What Happens Next**
          
          1. **ArgoCD Sync** (1-2 minutes):
             - ArgoCD detects the new repository
             - Syncs and creates the Kro RayService resource
             - RayService appears in ArgoCD UI
          
          2. **Kro Resource Orchestration** (3-5 minutes):
             - Namespace creation
             - Ray Service deployment
             - Kubernetes Service and Ingress setup
             - Ray cluster initialization
          
          3. **Ray Service Ready** (5-8 minutes total):
             - Ray Serve applications operational
             - HTTP endpoints available
             - Ray Dashboard accessible
             - Full monitoring and observability enabled
          
          ## üìã **Resource Overview**
          - **Service**: ${{ parameters.name }}
          - **Namespace**: ${{ parameters.namespace }}
          - **ArgoCD Project**: ${{ parameters.name }}-ray-project
          - **GitOps Repository**: ${{ parameters.name }}-ray-service
          - **Worker Replicas**: ${{ parameters.replicas }}
          - **Head Resources**: ${{ parameters.headCpu }}/${{ parameters.headMemory }}
          - **Worker Resources**: ${{ parameters.workerCpu }}/${{ parameters.workerMemory }}
          
          ## üîó **Next Steps**
          1. **Monitor ArgoCD**: Watch the application sync progress
          2. **Check Kro Status**: Verify RayService resource health
          3. **Test Endpoints**: Send requests to your Ray Serve applications
          4. **Scale Resources**: Adjust replicas and resources as needed
          5. **Explore Resources**: Use the links above to explore your infrastructure
          
          Your Ray Service is now fully integrated with Kro abstraction and GitOps! üéØ