apiVersion: scaffolder.backstage.io/v1beta3
kind: Template
metadata:
  description: |
    Deploy Ray Service on Kubernetes using Kro abstraction and GitOps.
    
    Choose between CPU (Transformers) or GPU (vLLM) deployment for AI model inference.
    Supports models from 1GB (TinyLlama) to 14GB (Mistral-7B) with automatic resource configuration.
    
    **Model Management:**
    - Models are pre-uploaded to S3 bucket (configured in system catalog-info.yaml)
    - Currently available: TinyLlama-1.1B (2GB), Mistral-7B-Instruct (13.5GB)
    - To add new models: Update ray-operator addon's model-prestage-job.yaml with new model upload job
    - Models are mounted via S3 CSI driver at /mnt/models/models/{model-name}
  name: ray-serve-kubernetes
  title: Ray Service on Kubernetes
spec:
  owner: guest
  type: service
  parameters:
    - title: Basic Configuration
      properties:
        name:
          title: Service Name
          type: string
          pattern: '^[a-z0-9][a-z0-9-]*[a-z0-9]$|^[a-z0-9]$'
          ui:help: 'Lowercase alphanumeric with hyphens, 1-63 characters'
        deploymentType:
          title: Deployment Type
          type: string
          default: "cpu"
          enum: ["cpu", "gpu"]
          enumNames:
            - "CPU - Transformers (smaller models)"
            - "GPU - vLLM (larger models, requires GPU nodes)"
        namespace:
          title: Namespace
          type: string
          default: ray-system
        replicas:
          title: Worker Replicas
          type: integer
          default: 2
          minimum: 1
          maximum: 10
        modelId:
          title: Model
          type: string
          default: "/mnt/models/models/tinyllama"
          enum:
            - "/mnt/models/models/tinyllama"
            - "/mnt/models/models/mistral-7b"
          enumNames:
            - "TinyLlama-1.1B (1GB, fast)"
            - "Mistral-7B-Instruct (14GB, high quality)"
        maxLength:
          title: Max Tokens
          type: string
          default: "100"
      required:
        - name
        - deploymentType
    - title: Resource Configuration
      properties:
        headCpu:
          title: Head CPU
          type: string
          default: "2"
        headMemory:
          title: Head Memory
          type: string
          default: "8Gi"
        workerCpu:
          title: Worker CPU
          type: string
          default: "4"
        workerMemory:
          title: Worker Memory
          type: string
          default: "16Gi"
        workerGpu:
          title: Worker GPU
          type: string
          default: "1"
          enum: ["0", "1"]
          enumNames:
            - "CPU only"
            - "1 GPU"
  steps:
    - id: validate-parameters
      name: Validate Parameters
      action: debug:log
      input:
        message: |
          Validating template parameters:
          - Service Name: ${{ parameters.name }}
          - Namespace: ${{ parameters.namespace }}
          - Ray Serve Config: ${{ parameters.rayServeFile }}
          - Worker Replicas: ${{ parameters.replicas }}
          - Head Resources: ${{ parameters.headCpu }}/${{ parameters.headMemory }}
          - Worker Resources: ${{ parameters.workerCpu }}/${{ parameters.workerMemory }}

    - id: fetchSystem
      name: Fetch System
      action: catalog:fetch
      input:
        entityRef: system:default/system-info

    - action: fetch:template
      name: Fetch Base
      id: fetch-base
      input:
        url: ./skeleton/
        values:
          name: ${{ parameters.name }}
          namespace: ${{ parameters.namespace }}
          modelId: ${{ parameters.modelId }}
          maxLength: ${{ parameters.maxLength }}
          rayServeFile: ${{ parameters.deploymentType === 'gpu' and 'https://github.com/aws-samples/appmod-blueprints/raw/763e8339/gitops/workloads/ray/gpu-serve-transformers.zip' or 'https://github.com/aws-samples/appmod-blueprints/raw/refs/heads/feat/eks-capabilities-squash/gitops/workloads/ray/cpu-serve-config.zip' }}
          replicas: ${{ parameters.replicas }}
          headCpu: ${{ parameters.headCpu }}
          headMemory: ${{ parameters.headMemory }}
          workerCpu: ${{ parameters.modelId === '/mnt/models/models/mistral-7b' and '8' or parameters.workerCpu }}
          workerMemory: ${{ parameters.modelId === '/mnt/models/models/mistral-7b' and '32Gi' or parameters.workerMemory }}
          headGpu: "0"
          workerGpu: ${{ parameters.workerGpu }}
          gitlab_hostname: ${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}
          ingress_hostname: ${{ steps['fetchSystem'].output.entity.spec.ingress_hostname }}
          argocd_hostname: ${{ steps['fetchSystem'].output.entity.spec.argocd_hostname }}
          git_username: ${{ steps['fetchSystem'].output.entity.spec.gituser }}
          aws_account_id: ${{ steps['fetchSystem'].output.entity.spec.aws_account_id }}
          aws_region: ${{ steps['fetchSystem'].output.entity.spec.aws_region }}
          resource_prefix: ${{ steps['fetchSystem'].output.entity.spec.resource_prefix }}
          model_s3_bucket: ${{ steps['fetchSystem'].output.entity.spec.model_s3_bucket }}
          created_by: ${{ user.entity.metadata.name | default("unknown") }}

    - id: publish
      name: Publishing to GitLab repository
      action: publish:gitlab
      input:
        repoUrl: ${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}?repo=${{parameters.name}}-ray-service&owner=${{ steps['fetchSystem'].output.entity.spec.gituser }}
        defaultBranch: main
        useCustomGit: true

    - id: create-argocd-project
      name: Create ArgoCD Project
      action: kube:apply
      input:
        namespaced: true
        manifest: |
          apiVersion: argoproj.io/v1alpha1
          kind: AppProject
          metadata:
            name: ${{parameters.name}}-ray-project
            namespace: argocd
            labels:
              app.kubernetes.io/name: ${{parameters.name}}
              app.kubernetes.io/component: ray-service
              app.kubernetes.io/managed-by: backstage
              backstage.io/template-name: ray-serve-kubernetes
            annotations:
              backstage.io/template-version: "1.0.0"
              backstage.io/created-by: ${{ user.entity.metadata.name | default("unknown") }}
          spec:
            destinations:
              - name: peeks-hub
                namespace: ${{ parameters.namespace }}
            sourceRepos:
              - https://${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}/${{ steps['fetchSystem'].output.entity.spec.gituser }}/${{parameters.name}}-ray-service.git
            sourceNamespaces:
              - argocd
            namespaceResourceWhitelist:
              - group: ""
                kind: Namespace
              - group: ""
                kind: Service
              - group: ""
                kind: ConfigMap
              - group: ""
                kind: Secret
              - group: apps
                kind: Deployment
              - group: kro.run
                kind: RayService
              - group: ray.io
                kind: RayService
              - group: ray.io
                kind: RayCluster
              - group: networking.k8s.io
                kind: Ingress
            roles:
              - name: admin
                policies:
                  - p, proj:${{parameters.name}}-ray-project:admin, applications, *, ${{parameters.name}}-ray-project/*, allow
                  - p, proj:${{parameters.name}}-ray-project:admin, repositories, *, *, allow
                groups:
                  - eks-argocd-admins
              - name: developer
                policies:
                  - p, proj:${{parameters.name}}-ray-project:developer, applications, get, ${{parameters.name}}-ray-project/*, allow
                  - p, proj:${{parameters.name}}-ray-project:developer, applications, sync, ${{parameters.name}}-ray-project/*, allow
                  - p, proj:${{parameters.name}}-ray-project:developer, repositories, get, *, allow
                groups:
                  - eks-argocd-developers

    - id: create-argocd-app
      name: Create ArgoCD Application (GitOps)
      action: kube:apply
      input:
        namespaced: true
        manifest: |
          apiVersion: argoproj.io/v1alpha1
          kind: Application
          metadata:
            name: ${{parameters.name}}-ray-service
            namespace: argocd
            labels:
              app.kubernetes.io/name: ${{parameters.name}}
              app.kubernetes.io/component: ray-service
              app.kubernetes.io/managed-by: backstage
              backstage.io/template-name: ray-serve-kubernetes
            annotations:
              backstage.io/template-version: "1.0.0"
              backstage.io/created-by: ${{ user.entity.metadata.name | default("unknown") }}
              argocd.argoproj.io/finalizer: resources-finalizer.argocd.argoproj.io
          spec:
            project: ${{parameters.name}}-ray-project
            source:
              repoURL: https://${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}/${{ steps['fetchSystem'].output.entity.spec.gituser }}/${{parameters.name}}-ray-service.git
              path: manifests
              targetRevision: HEAD
            destination:
              name: peeks-hub
              namespace: ${{ parameters.namespace }}
            syncPolicy:
              automated:
                prune: true
                selfHeal: true
              syncOptions:
                - CreateNamespace=true
                - PrunePropagationPolicy=foreground
                - PruneLast=true
              retry:
                limit: 5
                backoff:
                  duration: 5s
                  factor: 2
                  maxDuration: 3m
            ignoreDifferences:
              - group: kro.run
                kind: RayService
                jsonPointers:
                  - /status
              - group: ray.io
                kind: RayService
                jsonPointers:
                  - /status
              - group: ray.io
                kind: RayCluster
                jsonPointers:
                  - /status
            info:
              - name: 'Kro RayService Status'
                value: 'Check the RayService resource status for detailed information'

    - id: register
      name: Register
      action: catalog:register
      input:
        repoContentsUrl: https://${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}/${{ steps['fetchSystem'].output.entity.spec.gituser }}/${{parameters.name}}-ray-service/-/blob/main
        catalogInfoPath: "/catalog-info.yaml"

    - id: wait-for-sync
      name: Wait for Initial Sync
      action: debug:log
      input:
        message: |
          üîÑ **GitOps Deployment Initiated!**
          
          Your Ray Service is now being deployed via GitOps using ArgoCD and Kro abstraction. 
          The Kro RayService resource will be created and managed by ArgoCD, orchestrating 
          all required Kubernetes and Ray resources.
          
          ## üìä **Kro + GitOps Benefits**
          - ‚úÖ **High-Level Abstraction**: Single RayService resource manages everything
          - ‚úÖ **Full Visibility**: All resources appear in ArgoCD applications
          - ‚úÖ **Version Control**: All changes tracked in Git
          - ‚úÖ **Rollback Capability**: Easy rollback to previous versions
          - ‚úÖ **Drift Detection**: ArgoCD monitors and corrects configuration drift
          - ‚úÖ **Resource Orchestration**: Kro handles complex resource dependencies
          
          ## üîç **Monitoring Deployment**
          1. **ArgoCD Application**: Monitor sync status and health
          2. **Kro Resource Status**: Check RayService resource conditions
          3. **Ray Resources**: Watch Ray cluster and serve pods being created
          
          The ArgoCD application will automatically sync and create the Kro RayService resource,
          which will then orchestrate the creation of all required Ray and Kubernetes resources.

  output:
    links:
      - title: Open in catalog
        icon: catalog
        entityRef: ${{ steps['register'].output.entityRef }}
      - title: ArgoCD Application (GitOps)
        url: https://${{ steps['fetchSystem'].output.entity.spec.argocd_hostname }}/applications/${{ parameters.name }}-ray-service?resource=
        icon: web
      - title: GitLab Repository (GitOps Source)
        url: https://${{ steps['fetchSystem'].output.entity.spec.gitlab_hostname }}/${{ steps['fetchSystem'].output.entity.spec.gituser }}/${{ parameters.name }}-ray-service
        icon: git
      - title: ArgoCD Project
        url: https://${{ steps['fetchSystem'].output.entity.spec.argocd_hostname }}/settings/projects/${{ parameters.name }}-ray-project
        icon: web
      - title: Ray Serve Endpoint (After Deployment)
        url: https://${{ steps['fetchSystem'].output.entity.spec.ingress_hostname }}/ray-serve/${{ parameters.name }}/
        icon: web
      - title: Ray Dashboard (After Deployment)
        url: https://${{ steps['fetchSystem'].output.entity.spec.ingress_hostname }}/ray-dashboard/${{ parameters.name }}/
        icon: web
    text:
      - title: Kro-based Ray Service Deployment
        content: |
          üéâ **Kro + GitOps Ray Service Successfully Initiated!**
          
          Your Ray Service is now being deployed using Kro abstraction with GitOps principles. 
          This approach provides the highest level of automation and management capabilities.
          
          ## üîÑ **Kro + GitOps Workflow**
          1. **Repository Created**: GitLab repository with Kro RayService manifest
          2. **ArgoCD Application**: Monitors repository for changes
          3. **Automatic Sync**: ArgoCD deploys Kro RayService resource
          4. **Kro Orchestration**: RayService creates all required resources
          5. **Continuous Monitoring**: ArgoCD ensures desired state
          
          ## üìä **Key Advantages**
          
          ### **Kro Abstraction Benefits**
          - **Simplified Management**: Single resource manages complex Ray deployment
          - **Resource Orchestration**: Automatic dependency handling and ordering
          - **Status Aggregation**: Unified status across all managed resources
          - **Lifecycle Management**: Coordinated creation, updates, and deletion
          
          ### **GitOps Benefits**
          - **Version Control**: All configuration changes tracked in Git
          - **Rollback**: Easy rollback to any previous version
          - **Audit Trail**: Complete history of who changed what and when
          - **Drift Detection**: ArgoCD automatically corrects configuration drift
          
          ### **Enhanced Management**
          - **Declarative**: Infrastructure as Code approach
          - **Reproducible**: Consistent deployments across environments
          - **Scalable**: Easy to replicate for multiple Ray Services
          
          ## üöÄ **What Happens Next**
          
          1. **ArgoCD Sync** (1-2 minutes):
             - ArgoCD detects the new repository
             - Syncs and creates the Kro RayService resource
             - RayService appears in ArgoCD UI
          
          2. **Kro Resource Orchestration** (3-5 minutes):
             - Namespace creation
             - Ray Service deployment
             - Kubernetes Service and Ingress setup
             - Ray cluster initialization
          
          3. **Ray Service Ready** (5-8 minutes total):
             - Ray Serve applications operational
             - HTTP endpoints available
             - Ray Dashboard accessible
             - Full monitoring and observability enabled
          
          ## üìã **Resource Overview**
          - **Service**: ${{ parameters.name }}
          - **Namespace**: ${{ parameters.namespace }}
          - **ArgoCD Project**: ${{ parameters.name }}-ray-project
          - **GitOps Repository**: ${{ parameters.name }}-ray-service
          - **Worker Replicas**: ${{ parameters.replicas }}
          - **Head Resources**: ${{ parameters.headCpu }}/${{ parameters.headMemory }}
          - **Worker Resources**: ${{ parameters.workerCpu }}/${{ parameters.workerMemory }}
          
          ## üîó **Next Steps**
          1. **Monitor ArgoCD**: Watch the application sync progress
          2. **Check Kro Status**: Verify RayService resource health
          3. **Test Endpoints**: Send requests to your Ray Serve applications
          4. **Scale Resources**: Adjust replicas and resources as needed
          5. **Explore Resources**: Use the links above to explore your infrastructure
          
          ## üß™ **Test Your Endpoint**
          
          Once deployed (5-8 minutes), test your inference endpoint:
          
          ```bash
          curl -X POST https://${{ steps['fetchSystem'].output.entity.spec.ingress_hostname }}/ray-serve/${{ parameters.name }}/generate \
            -H "Content-Type: application/json" \
            -d '{"prompt": "Explain machine learning in simple terms", "max_length": 100}'
          ```
          
          **Expected Response:**
          ```json
          {
            "prompt": "Explain machine learning in simple terms",
            "generated_text": "Explain machine learning in simple terms: ...",
            "model": "${{ parameters.modelId }}",
            "device": "cuda:0"
          }
          ```
          
          **Troubleshooting:**
          - If 404: Service still deploying, wait 2-3 more minutes
          - If 502: Ray Serve not ready, check ArgoCD sync status
          - If timeout: Check pod status with `kubectl get pods -n ${{ parameters.namespace }}`
          
          Your Ray Service is now fully integrated with Kro abstraction and GitOps! üéØ