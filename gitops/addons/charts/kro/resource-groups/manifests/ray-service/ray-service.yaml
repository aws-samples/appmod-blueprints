apiVersion: kro.run/v1alpha1
kind: ResourceGraphDefinition
metadata:
  name: rayservice.kro.run
  annotations:
    argocd.argoproj.io/sync-options: Replace=false
    argocd.argoproj.io/sync-wave: "0"
spec:
  resources:
  # CPU RayService - no GPU resources
  - id: rayserviceCpu
    includeWhen:
    - ${schema.spec.resources.worker.gpu == "0"}
    readyWhen:
    - ${rayserviceCpu.metadata.name != ""}
    template:
      apiVersion: ray.io/v1
      kind: RayService
      metadata:
        annotations:
          argocd.argoproj.io/tracking-id: ${schema.metadata.?annotations["argocd.argoproj.io/tracking-id"].orValue("")}
          backstage.io/created-by: ${schema.spec.createdBy}
          backstage.io/template-version: 1.0.0
          ray.io/serve-config-source: ${schema.spec.rayServeFile}
        labels:
          app.kubernetes.io/component: ray-service
          app.kubernetes.io/managed-by: kro
          app.kubernetes.io/name: ${schema.spec.name}
          backstage.io/template-name: ray-service-kro
        name: ray-service-${schema.spec.name}
        namespace: ${schema.metadata.namespace}
        ownerReferences:
        - apiVersion: kro.run/v1alpha1
          blockOwnerDeletion: true
          controller: false
          kind: RayService
          name: ${schema.metadata.name}
          uid: ${schema.metadata.uid}
      spec:
        deploymentUnhealthySecondThreshold: 1200
        rayClusterConfig:
          autoscalerOptions:
            idleTimeoutSeconds: 120
            upscalingMode: Conservative
          enableInTreeAutoscaling: true
          headGroupSpec:
            rayStartParams:
              dashboard-host: 0.0.0.0
              num-cpus: "0"
            template:
              metadata:
                labels:
                  app.kubernetes.io/component: ray-head
                  app.kubernetes.io/name: ${schema.spec.name}
                  backstage.io/template-name: ray-service-kro
              spec:
                containers:
                - image: rayproject/ray:2.34.0
                  name: ray-head
                  ports:
                  - containerPort: 6379
                    name: gcs-server
                  - containerPort: 8265
                    name: dashboard
                  - containerPort: 10001
                    name: client
                  - containerPort: 8000
                    name: serve
                  resources:
                    limits:
                      cpu: ${schema.spec.resources.head.cpu}
                      memory: ${schema.spec.resources.head.memory}
                    requests:
                      cpu: ${schema.spec.resources.head.cpu}
                      memory: ${schema.spec.resources.head.memory}
          rayVersion: 2.24.0
          workerGroupSpecs:
          - groupName: worker-group
            maxReplicas: ${schema.spec.replicas * 2}
            minReplicas: 1
            rayStartParams: {}
            replicas: ${schema.spec.replicas}
            template:
              metadata:
                labels:
                  app.kubernetes.io/component: ray-worker
                  app.kubernetes.io/name: ${schema.spec.name}
                  backstage.io/template-name: ray-service-kro
              spec:
                containers:
                - image: rayproject/ray:2.34.0
                  lifecycle:
                    preStop:
                      exec:
                        command:
                        - /bin/sh
                        - -c
                        - ray stop
                  name: ray-worker
                  resources:
                    limits:
                      cpu: ${schema.spec.resources.worker.cpu}
                      memory: ${schema.spec.resources.worker.memory}
                    requests:
                      cpu: ${schema.spec.resources.worker.cpu}
                      memory: ${schema.spec.resources.worker.memory}
        serveConfigV2: |
          applications:
            - name: gpu_text_generation
              import_path: app:deployment
              route_prefix: /generate
              runtime_env:
                working_dir: "${schema.spec.rayServeFile}"
                pip:
                  - torch>=2.0.0
                  - transformers>=4.30.0
                  - accelerate
                  - bitsandbytes
                env_vars:
                  MODEL_ID: "${schema.spec.modelId}"
                  MAX_LENGTH: "${schema.spec.maxLength}"
        serviceUnhealthySecondThreshold: 1200
  # GPU RayService - with GPU resources
  - id: rayserviceGpu
    includeWhen:
    - ${schema.spec.resources.worker.gpu != "0"}
    readyWhen:
    - ${rayserviceGpu.metadata.name != ""}
    template:
      apiVersion: ray.io/v1
      kind: RayService
      metadata:
        annotations:
          argocd.argoproj.io/tracking-id: ${schema.metadata.?annotations["argocd.argoproj.io/tracking-id"].orValue("")}
          backstage.io/created-by: ${schema.spec.createdBy}
          backstage.io/template-version: 1.0.0
          ray.io/serve-config-source: ${schema.spec.rayServeFile}
        labels:
          app.kubernetes.io/component: ray-service
          app.kubernetes.io/managed-by: kro
          app.kubernetes.io/name: ${schema.spec.name}
          backstage.io/template-name: ray-service-kro
        name: ray-service-${schema.spec.name}
        namespace: ${schema.metadata.namespace}
        ownerReferences:
        - apiVersion: kro.run/v1alpha1
          blockOwnerDeletion: true
          controller: false
          kind: RayService
          name: ${schema.metadata.name}
          uid: ${schema.metadata.uid}
      spec:
        deploymentUnhealthySecondThreshold: 1200
        rayClusterConfig:
          autoscalerOptions:
            idleTimeoutSeconds: 120
            upscalingMode: Conservative
          enableInTreeAutoscaling: true
          headGroupSpec:
            rayStartParams:
              dashboard-host: 0.0.0.0
              num-cpus: "0"
            template:
              metadata:
                labels:
                  app.kubernetes.io/component: ray-head
                  app.kubernetes.io/name: ${schema.spec.name}
                  backstage.io/template-name: ray-service-kro
              spec:
                containers:
                - image: public.ecr.aws/data-on-eks/ray2.24.0-py310-vllm-gpu:v1
                  name: ray-head
                  ports:
                  - containerPort: 6379
                    name: gcs-server
                  - containerPort: 8265
                    name: dashboard
                  - containerPort: 10001
                    name: client
                  - containerPort: 8000
                    name: serve
                  resources:
                    limits:
                      cpu: ${schema.spec.resources.head.cpu}
                      memory: ${schema.spec.resources.head.memory}
                    requests:
                      cpu: ${schema.spec.resources.head.cpu}
                      memory: ${schema.spec.resources.head.memory}
          rayVersion: 2.24.0
          workerGroupSpecs:
          - groupName: worker-group
            maxReplicas: ${schema.spec.replicas * 2}
            minReplicas: 1
            rayStartParams: {}
            replicas: ${schema.spec.replicas}
            template:
              metadata:
                labels:
                  app.kubernetes.io/component: ray-worker
                  app.kubernetes.io/name: ${schema.spec.name}
                  backstage.io/template-name: ray-service-kro
              spec:
                containers:
                - image: rayproject/ray:2.24.0-py310-cu118
                  env:
                  - name: HUGGING_FACE_HUB_TOKEN
                    value: ${schema.spec.hfToken}
                  lifecycle:
                    preStop:
                      exec:
                        command:
                        - /bin/sh
                        - -c
                        - ray stop
                  name: ray-worker
                  resources:
                    limits:
                      cpu: ${schema.spec.resources.worker.cpu}
                      memory: ${schema.spec.resources.worker.memory}
                      nvidia.com/gpu: ${schema.spec.resources.worker.gpu}
                    requests:
                      cpu: ${schema.spec.resources.worker.cpu}
                      memory: ${schema.spec.resources.worker.memory}
                      nvidia.com/gpu: ${schema.spec.resources.worker.gpu}
        serveConfigV2: |
          applications:
            - name: gpu_text_generation
              import_path: vllm_serve:deployment
              route_prefix: /generate
              runtime_env:
                working_dir: "${schema.spec.rayServeFile}"
                pip:
                  - vllm==0.4.3
                env_vars:
                  MODEL_ID: "${schema.spec.modelId}"
                  MAX_MODEL_LEN: "${schema.spec.maxLength}"
                  LD_LIBRARY_PATH: "/home/ray/anaconda3/lib:$LD_LIBRARY_PATH"
        serviceUnhealthySecondThreshold: 1200
  - id: serveservice
    readyWhen:
    - ${serveservice.metadata.name != ""}
    template:
      apiVersion: v1
      kind: Service
      metadata:
        annotations:
          argocd.argoproj.io/tracking-id: ${schema.metadata.?annotations["argocd.argoproj.io/tracking-id"].orValue("")}
          backstage.io/created-by: ${schema.spec.createdBy}
          backstage.io/template-version: 1.0.0
        labels:
          app.kubernetes.io/component: ray-service
          app.kubernetes.io/managed-by: kro
          app.kubernetes.io/name: ${schema.spec.name}
          backstage.io/template-name: ray-service-kro
        name: ${schema.spec.name}-ray-serve-svc
        namespace: ${schema.metadata.namespace}
        ownerReferences:
        - apiVersion: kro.run/v1alpha1
          blockOwnerDeletion: true
          controller: false
          kind: RayService
          name: ${schema.metadata.name}
          uid: ${schema.metadata.uid}
      spec:
        ports:
        - name: serve
          port: 8000
          protocol: TCP
          targetPort: 8000
        - name: dashboard
          port: 8265
          protocol: TCP
          targetPort: 8265
        selector:
          app.kubernetes.io/component: ray-head
          app.kubernetes.io/name: ${schema.spec.name}
        type: ClusterIP
  - id: rayingress
    readyWhen:
    - ${rayingress.metadata.name != ""}
    template:
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        annotations:
          argocd.argoproj.io/tracking-id: ${schema.metadata.?annotations["argocd.argoproj.io/tracking-id"].orValue("")}
          backstage.io/created-by: ${schema.spec.createdBy}
          backstage.io/template-version: 1.0.0
          nginx.ingress.kubernetes.io/rewrite-target: /$2
          nginx.ingress.kubernetes.io/use-regex: "true"
          nginx.ingress.kubernetes.io/proxy-connect-timeout: "600"
          nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
          nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
        labels:
          app.kubernetes.io/component: ray-service
          app.kubernetes.io/managed-by: kro
          app.kubernetes.io/name: ${schema.spec.name}
          backstage.io/template-name: ray-service-kro
        name: ${schema.spec.name}-ray-ingress
        namespace: ${schema.metadata.namespace}
        ownerReferences:
        - apiVersion: kro.run/v1alpha1
          blockOwnerDeletion: true
          controller: false
          kind: RayService
          name: ${schema.metadata.name}
          uid: ${schema.metadata.uid}
      spec:
        ingressClassName: nginx
        rules:
        - host: ${schema.spec.ingressHostname}
          http:
            paths:
            - backend:
                service:
                  name: ${schema.spec.name}-ray-serve-svc
                  port:
                    number: 8000
              path: /ray-serve/${schema.spec.name}(/|$)(.*)
              pathType: ImplementationSpecific
            - backend:
                service:
                  name: ${schema.spec.name}-ray-serve-svc
                  port:
                    number: 8265
              path: /ray-dashboard/${schema.spec.name}(/|$)(.*)
              pathType: ImplementationSpecific
  schema:
    apiVersion: v1alpha1
    group: kro.run
    kind: RayService
    spec:
      createdBy: string | default="unknown"
      gitlab:
        hostname: string
        username: string
      hfToken: string | default=""
      ingressHostname: string
      name: string
      modelId: string | default="microsoft/DialoGPT-medium"
      maxLength: string | default="100"
      rayServeFile: string | default="https://github.com/aws-samples/appmod-blueprints/raw/refs/heads/feat/eks-capabilities-squash/gitops/workloads/ray/cpu-serve-config.zip"
      replicas: integer | default=2
      resources:
        head:
          cpu: string | default="1"
          memory: string | default="2Gi"
        worker:
          cpu: string | default="500m"
          gpu: string | default="0"
          memory: string | default="1Gi"
    status:
      ingressName: ${rayingress.metadata.name}
      rayServiceCpuName: ${rayserviceCpu.metadata.name}
      rayServiceGpuName: ${rayserviceGpu.metadata.name}
      serveServiceName: ${serveservice.metadata.name}
